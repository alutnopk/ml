{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26ab145a",
      "metadata": {
        "id": "26ab145a"
      },
      "outputs": [],
      "source": [
        "# Group Number: 2\n",
        "# Group Members:\n",
        "# Kartik Pontula (20CS10031)\n",
        "# Adarsh (19EC39002)\n",
        "# Project Title: Credit Approval using Decision Tree based Learning Model\n",
        "# Project Code: CADT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "909b83ff",
      "metadata": {
        "id": "909b83ff"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59020a61",
      "metadata": {
        "id": "59020a61"
      },
      "outputs": [],
      "source": [
        "# Function definitions\n",
        "def maxCountArg(y):\n",
        "\tunique_values, counts = np.unique(y, return_counts=True)\n",
        "\t# Find the index of the maximum count\n",
        "\tmax_count_index = np.argmax(counts)\n",
        "\t# Retrieve the value with the maximum count\n",
        "\tvalue_with_max_count = unique_values[max_count_index]\n",
        "\treturn value_with_max_count\n",
        "\n",
        "def calculate_entropy(y):\n",
        "\tunique_classes, class_counts = np.unique(y, return_counts=True)\n",
        "\tprobabilities = class_counts / len(y)\n",
        "\tentropy = -np.sum(probabilities * np.log2(probabilities))\n",
        "\treturn entropy\n",
        "\n",
        "def gini_index(labels):\n",
        "\tunique_classes = np.unique(labels)\n",
        "\tgini = 1.0 - sum(((np.sum(labels == c))/(len(labels)))**2 for c in unique_classes)\n",
        "\treturn gini"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision tree implementation\n",
        "class DecisionTree:\n",
        "\tdef __init__(self, max_depth=None,scoring=gini_index):\n",
        "\t\tself.max_depth = max_depth\n",
        "\t\tself.scoring = scoring\n",
        "\n",
        "\tdef fit(self, X, y):\n",
        "\t\tself.tree = self._grow_tree(X, y)\n",
        "\n",
        "\tdef _grow_tree(self, X, y, depth=0):\n",
        "\t\tn_samples, n_features = X.shape\n",
        "\t\tunique_classes = np.unique(y)\n",
        "\n",
        "\t\tif len(unique_classes) == 1 or (self.max_depth is not None and depth == self.max_depth):\n",
        "\t\t\treturn {'class': maxCountArg(y)}\n",
        "\n",
        "\t\tbest_feature, best_threshold = self._best_split(X, y)\n",
        "\n",
        "\t\tleft_indices = X[:, best_feature] <= best_threshold\n",
        "\t\tright_indices = ~left_indices\n",
        "\n",
        "\t\tif len(y) == np.count_nonzero(left_indices):\n",
        "\t\t\treturn {'class': maxCountArg(y)}\n",
        "\t\telif len(y) == np.count_nonzero(right_indices):\n",
        "\t\t\treturn {'class': maxCountArg(y)}\n",
        "\n",
        "\t\t#print(\"prob left\")\n",
        "\t\tleft_subtree = self._grow_tree(X[left_indices], y[left_indices], depth + 1)\n",
        "\t\t#print(\"prob right\",best_feature,best_threshold,X,y[right_indices],y[left_indices])\n",
        "\t\tright_subtree = self._grow_tree(X[right_indices], y[right_indices], depth + 1)\n",
        "\n",
        "\t\tnode = {'feature_index': best_feature, 'threshold': best_threshold,\n",
        "\t\t\t\t'left': left_subtree, 'right': right_subtree}\n",
        "\n",
        "\t\treturn node\n",
        "\n",
        "\tdef _best_split(self, X, y):\n",
        "\t\tn_samples, n_features = X.shape\n",
        "\t\tbest_info_gain = -float('inf')\n",
        "\t\tbest_feature = None\n",
        "\t\tbest_threshold = None\n",
        "\n",
        "\t\tentropy_parent = self.scoring(y)\n",
        "\n",
        "\t\tfor feature in range(n_features):\n",
        "\t\t\tthresholds = np.unique(X[:, feature])\n",
        "\t\t\tfor threshold in thresholds:\n",
        "\t\t\t\tleft_indices = X[:, feature] <= threshold\n",
        "\t\t\t\tright_indices = ~left_indices\n",
        "\n",
        "\t\t\t\tentropy_left = self.scoring(y[left_indices])\n",
        "\t\t\t\tentropy_right = self.scoring(y[right_indices])\n",
        "\n",
        "\t\t\t\tinfo_gain = entropy_parent - ((np.sum(left_indices) / n_samples) * entropy_left +\n",
        "\t\t\t\t\t\t\t\t\t\t\t  (np.sum(right_indices) / n_samples) * entropy_right)\n",
        "\n",
        "\t\t\t\tif info_gain > best_info_gain:\n",
        "\t\t\t\t\tbest_info_gain = info_gain\n",
        "\t\t\t\t\tbest_feature = feature\n",
        "\t\t\t\t\tbest_threshold = threshold\n",
        "\n",
        "\t\treturn best_feature, best_threshold\n",
        "\n",
        "\tdef predict(self, X):\n",
        "\t\treturn np.array([self._predict_sample(x, self.tree) for x in X])\n",
        "\n",
        "\tdef _predict_sample(self, sample, node):\n",
        "\t\tif 'class' in node:\n",
        "\t\t\treturn node['class']\n",
        "\t\telse:\n",
        "\t\t\tfeature_index = node['feature_index']\n",
        "\t\t\tthreshold = node['threshold']\n",
        "\t\t\tif sample[feature_index] <= threshold:\n",
        "\t\t\t\treturn self._predict_sample(sample, node['left'])\n",
        "\t\t\telse:\n",
        "\t\t\t\treturn self._predict_sample(sample, node['right'])\n",
        "\n",
        "\tdef prune(self, X, y):\n",
        "\t\tself._prune(self.tree, X, y)\n",
        "\n",
        "\tdef _prune(self, node, X, y):\n",
        "\t\tif 'class' in node:\n",
        "\t\t\treturn\n",
        "\n",
        "\t\tfeature_index = node['feature_index']\n",
        "\t\tthreshold = node['threshold']\n",
        "\n",
        "\t\tleft_indices = X[:, feature_index] <= threshold\n",
        "\t\tright_indices = ~left_indices\n",
        "\n",
        "\t\t# Prune the left and right subtrees\n",
        "\t\tself._prune(node['left'], X[left_indices], y[left_indices])\n",
        "\t\tself._prune(node['right'], X[right_indices], y[right_indices])\n",
        "\n",
        "\t\t# Check if pruning this node improves accuracy\n",
        "\t\toriginal_accuracy = self._accuracy(y, self.predict(X))\n",
        "\n",
        "\t\t# Temporarily prune this node\n",
        "\t\toriginal_node = node.copy()\n",
        "\t\tnode.clear()\n",
        "\t\tnode['class'] = maxCountArg(y)\n",
        "\n",
        "\t\tpruned_accuracy = self._accuracy(y, self.predict(X))\n",
        "\n",
        "\t\t# If accuracy decreased, revert pruning\n",
        "\t\tif pruned_accuracy < original_accuracy:\n",
        "\t\t\tnode.clear()\n",
        "\t\t\tnode.update(original_node)\n",
        "\n",
        "\tdef _accuracy(self, y_true, y_pred):\n",
        "\t\treturn np.sum(y_true == y_pred) / len(y_true)"
      ],
      "metadata": {
        "id": "16Qrd_Wy0WJt"
      },
      "id": "16Qrd_Wy0WJt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f188c6af",
      "metadata": {
        "id": "f188c6af"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data\"\n",
        "names = [\"A1\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\", \"A9\", \"A10\", \"A11\", \"A12\", \"A13\", \"A14\", \"A15\", \"class\"]\n",
        "data = pd.read_csv(url, names=names)\n",
        "\n",
        "# Replace missing values ('?') with NaN\n",
        "data.replace('?', np.nan, inplace=True)\n",
        "\n",
        "# Convert A2, A3, A8, A11, A14, A15 to numeric and handle missing values\n",
        "continuous_features = [\"A2\", \"A3\", \"A8\", \"A11\", \"A14\", \"A15\"]\n",
        "for feature in continuous_features:\n",
        "\tdata[feature] = pd.to_numeric(data[feature], errors='coerce')\n",
        "\n",
        "# Discretize continuous features using median\n",
        "for feature in continuous_features:\n",
        "\tmedian = data[feature].median()\n",
        "\tdata[feature] = data[feature].fillna(median)\n",
        "\tdata[feature] = pd.cut(data[feature], bins=3, labels=[i for i in range(3)])\n",
        "\n",
        "# Convert categorical features to one-hot encoding\n",
        "categorical_features = [\"A1\", \"A4\", \"A5\", \"A6\", \"A7\", \"A9\", \"A10\", \"A12\", \"A13\"]\n",
        "data = pd.get_dummies(data, columns=categorical_features, drop_first=True)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X = data.drop('class', axis=1).values\n",
        "y = data['class'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8daa5b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8daa5b4",
        "outputId": "0e76fa40-abb3-4e0f-a738-adf10a1c4daa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Decision Tree (Information Gain):\n",
            "Train Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.91      0.95      0.93       237\n",
            "           -       0.96      0.93      0.95       315\n",
            "\n",
            "    accuracy                           0.94       552\n",
            "   macro avg       0.94      0.94      0.94       552\n",
            "weighted avg       0.94      0.94      0.94       552\n",
            "\n",
            "Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.87      0.74      0.80        70\n",
            "           -       0.77      0.88      0.82        68\n",
            "\n",
            "    accuracy                           0.81       138\n",
            "   macro avg       0.82      0.81      0.81       138\n",
            "weighted avg       0.82      0.81      0.81       138\n",
            "\n",
            "***************************************************************************\n",
            "Classification Report for Decision Tree (Information Gain) after Pruning:\n",
            "Train Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.94      0.92      0.93       237\n",
            "           -       0.94      0.95      0.95       315\n",
            "\n",
            "    accuracy                           0.94       552\n",
            "   macro avg       0.94      0.94      0.94       552\n",
            "weighted avg       0.94      0.94      0.94       552\n",
            "\n",
            "Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.90      0.74      0.81        70\n",
            "           -       0.78      0.91      0.84        68\n",
            "\n",
            "    accuracy                           0.83       138\n",
            "   macro avg       0.84      0.83      0.83       138\n",
            "weighted avg       0.84      0.83      0.82       138\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Train the decision tree model using information gain\n",
        "dt = DecisionTree(max_depth=10, scoring=calculate_entropy) # scoring can be calculate_entropy or gini_index\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_train = dt.predict(X_train)\n",
        "y_pred_test = dt.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Classification Report for Decision Tree (Information Gain):\")\n",
        "print(\"Train Set:\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(\"Test Set:\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n",
        "print('*' * 75)\n",
        "\n",
        "# Prune the decision tree\n",
        "dt.prune(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_train = dt.predict(X_train)\n",
        "y_pred_test = dt.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Classification Report for Decision Tree (Information Gain) after Pruning:\")\n",
        "print(\"Train Set:\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(\"Test Set:\")\n",
        "print(classification_report(y_test, y_pred_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecd90669-f77f-45fe-9f0c-103a65367eab",
        "id": "t57zEfl71pHS"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Decision Tree (Gini Index):\n",
            "Train Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.94      0.95      0.94       237\n",
            "           -       0.96      0.95      0.96       315\n",
            "\n",
            "    accuracy                           0.95       552\n",
            "   macro avg       0.95      0.95      0.95       552\n",
            "weighted avg       0.95      0.95      0.95       552\n",
            "\n",
            "Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.88      0.74      0.81        70\n",
            "           -       0.77      0.90      0.83        68\n",
            "\n",
            "    accuracy                           0.82       138\n",
            "   macro avg       0.83      0.82      0.82       138\n",
            "weighted avg       0.83      0.82      0.82       138\n",
            "\n",
            "***************************************************************************\n",
            "Classification Report for Decision Tree (Gini Index) after Pruning:\n",
            "Train Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.94      0.94      0.94       237\n",
            "           -       0.96      0.96      0.96       315\n",
            "\n",
            "    accuracy                           0.95       552\n",
            "   macro avg       0.95      0.95      0.95       552\n",
            "weighted avg       0.95      0.95      0.95       552\n",
            "\n",
            "Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.88      0.74      0.81        70\n",
            "           -       0.77      0.90      0.83        68\n",
            "\n",
            "    accuracy                           0.82       138\n",
            "   macro avg       0.83      0.82      0.82       138\n",
            "weighted avg       0.83      0.82      0.82       138\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Train the decision tree model using Gini index\n",
        "dt = DecisionTree(max_depth=10, scoring=gini_index)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_train = dt.predict(X_train)\n",
        "y_pred_test = dt.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Classification Report for Decision Tree (Gini Index):\")\n",
        "print(\"Train Set:\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(\"Test Set:\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n",
        "print('*' * 75)\n",
        "\n",
        "# Prune the decision tree\n",
        "dt.prune(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_train = dt.predict(X_train)\n",
        "y_pred_test = dt.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Classification Report for Decision Tree (Gini Index) after Pruning:\")\n",
        "print(\"Train Set:\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(\"Test Set:\")\n",
        "print(classification_report(y_test, y_pred_test))"
      ],
      "id": "t57zEfl71pHS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55ea088d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55ea088d",
        "outputId": "6028e457-0850-4d5b-8745-57a702473883"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for scikit-learn DecisionTreeClassifier:\n",
            "Train Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.95      0.99      0.97       237\n",
            "           -       0.99      0.96      0.98       315\n",
            "\n",
            "    accuracy                           0.97       552\n",
            "   macro avg       0.97      0.98      0.97       552\n",
            "weighted avg       0.97      0.97      0.97       552\n",
            "\n",
            "Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           +       0.84      0.74      0.79        70\n",
            "           -       0.76      0.85      0.81        68\n",
            "\n",
            "    accuracy                           0.80       138\n",
            "   macro avg       0.80      0.80      0.80       138\n",
            "weighted avg       0.80      0.80      0.80       138\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Initialize the scikit-learn DecisionTreeClassifier\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Fit the model to the training data\n",
        "dt_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the training and test data\n",
        "y_pred_train = dt_clf.predict(X_train)\n",
        "y_pred_test = dt_clf.predict(X_test)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report for scikit-learn DecisionTreeClassifier:\")\n",
        "print(\"Train Set:\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(\"Test Set:\")\n",
        "print(classification_report(y_test, y_pred_test))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}